<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>task queue on Queensferry&#39;s Blog</title>
    <link>/tags/task-queue/</link>
    <description>Recent content in task queue on Queensferry&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 31 Mar 2019 16:40:16 +0000</lastBuildDate>
    
	<atom:link href="/tags/task-queue/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Flask &#43; Celery &#43; Redis 实现异步处理任务队列</title>
      <link>/posts/technique/web/backend/flask-celery-redis-%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97/</link>
      <pubDate>Sun, 31 Mar 2019 16:40:16 +0000</pubDate>
      
      <guid>/posts/technique/web/backend/flask-celery-redis-%E5%AE%9E%E7%8E%B0%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97/</guid>
      <description>&lt;p&gt;最近正在尝试编写网站，其中一个功能是帮助用户从某个 URL 抓取信息 —— 也就是爬虫 。但众所周知，爬虫程序由于 I/O 阻塞通常会消耗较长的时间，无法第一时间对用户请求作出响应 。因此我们会希望让爬虫任务在后台处理，等到执行成功/失败后再将结果返回给用户；而&lt;strong&gt;任务队列&lt;/strong&gt;就作为 Web 后端接口与爬虫处理程序之间的一个中介，负责传输任务的具体内容和执行结果 。这篇博客不会具体阐述 Flask Web 开发或 Python 爬虫的相关技术，而将重点聚焦于使用流行的开源异步任务处理框架 &lt;code&gt;Celery&lt;/code&gt; 实现一个任务队列的基本功能 。&lt;/p&gt;

&lt;p&gt;（我才不是出于咕咕咕的负罪感连更博客的）&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>